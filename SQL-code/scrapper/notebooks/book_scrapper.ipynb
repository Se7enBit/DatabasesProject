{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1e8ad100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5006df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ianos.gr/books/epistimes/pliroforiki?product_list_limit=60'\n",
    "\n",
    "result = requests.get(url)\n",
    "soup = BeautifulSoup(result.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "735f3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.findAll('a',\n",
    "                     attrs={'class': 'product-item-link'},\n",
    "                     href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6b3ce7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = []\n",
    "abstract_list = []\n",
    "image_list = []\n",
    "for i,row in enumerate(table):\n",
    "    book_url = row['href']\n",
    "    request_book = requests.get(book_url)\n",
    "    new_soup = BeautifulSoup(request_book.text,\n",
    "                             \"html.parser\")\n",
    "    \n",
    "    #Scrape for abstract\n",
    "    abstract_body = new_soup.find('div',\n",
    "                                attrs={'class': 'product attribute overview'})\n",
    "    abstract = abstract_body.find('div',\n",
    "                              attrs={'class': 'value'}).getText()\n",
    "    abstract_list.append(abstract)\n",
    "    \n",
    "    #Scrape for images\n",
    "    image_body = new_soup.find('div',\n",
    "                        attrs={'class': 'sw-product-top-section'})\n",
    "    image = image_body.find('img',\n",
    "               attrs={'class': 'gallery-placeholder__image'},\n",
    "               src=True)\n",
    "    img_url = image['src']\n",
    "    img = Image.open(requests.get(img_url, stream = True).raw)\n",
    "    img.save(f'images/{i}.png')\n",
    "    image_list.append(f'images/{i}.png')\n",
    "\n",
    "    #Scrape for data\n",
    "    new_table = new_soup.find('table',\n",
    "                              attrs={'class': 'data table additional-attributes'})\n",
    "    new_table_body = new_table.find('tbody')\n",
    "    headers = [header.text\n",
    "               for header in new_table_body.find_all('th')]\n",
    "    d_body = [body.text\n",
    "               for body in new_table_body.find_all('td')]\n",
    "    book_data = {headers[n]:d_body[n] for n in range(len(d_body))}\n",
    "\n",
    "    json_output.append(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a522db",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = []\n",
    "abstract_list = []\n",
    "image_list = []\n",
    "for i,row in enumerate(table):\n",
    "    book_url = row['href']\n",
    "    request_book = requests.get(book_url)\n",
    "    new_soup = BeautifulSoup(request_book.text,\n",
    "                             \"html.parser\")\n",
    "    \n",
    "    #Scrape for abstract\n",
    "    abstract_body = new_soup.find('div',\n",
    "                                attrs={'class': 'product attribute overview'})\n",
    "    abstract = abstract_body.find('div',\n",
    "                              attrs={'class': 'value'}).getText()\n",
    "    abstract_list.append(abstract)\n",
    "    \n",
    "    #Scrape for images\n",
    "    image_body = new_soup.find('div',\n",
    "                        attrs={'class': 'sw-product-top-section'})\n",
    "    image = image_body.find('img',\n",
    "               attrs={'class': 'gallery-placeholder__image'},\n",
    "               src=True)\n",
    "    img_url = image['src']\n",
    "    img = Image.open(requests.get(img_url, stream = True).raw)\n",
    "    img.save(f'images/{i}.png')\n",
    "    image_list.append(f'images/{i}.png')\n",
    "\n",
    "    #Scrape for data\n",
    "    new_table = new_soup.find('table',\n",
    "                              attrs={'class': 'data table additional-attributes'})\n",
    "    new_table_body = new_table.find('tbody')\n",
    "    headers = [header.text\n",
    "               for header in new_table_body.find_all('th')]\n",
    "    d_body = [body.text\n",
    "               for body in new_table_body.find_all('td')]\n",
    "    book_data = {headers[n]:d_body[n] for n in range(len(d_body))}\n",
    "\n",
    "    json_output.append(book_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f211c",
   "metadata": {},
   "source": [
    "# ________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012e35c",
   "metadata": {},
   "source": [
    "## Second URL for more books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "232ae57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ianos.gr/books/epistimes/pliroforiki?p=2&product_list_limit=60'\n",
    "\n",
    "result = requests.get(url)\n",
    "soup = BeautifulSoup(result.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "af0595c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.findAll('a',\n",
    "                     attrs={'class': 'product-item-link'},\n",
    "                     href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "060bef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in enumerate(table):\n",
    "    book_url = row['href']\n",
    "    request_book = requests.get(book_url)\n",
    "    new_soup = BeautifulSoup(request_book.text,\n",
    "                             \"html.parser\")\n",
    "    \n",
    "    #Scrape for abstract\n",
    "    abstract_body = new_soup.find('div',\n",
    "                                attrs={'class': 'product attribute overview'})\n",
    "    abstract = abstract_body.find('div',\n",
    "                              attrs={'class': 'value'}).getText()\n",
    "    abstract_list.append(abstract)\n",
    "    \n",
    "    #Scrape for images\n",
    "    image_body = new_soup.find('div',\n",
    "                        attrs={'class': 'sw-product-top-section'})\n",
    "    image = image_body.find('img',\n",
    "               attrs={'class': 'gallery-placeholder__image'},\n",
    "               src=True)\n",
    "    img_url = image['src']\n",
    "    img = Image.open(requests.get(img_url, stream = True).raw)\n",
    "    img.save(f'images/{i+60}.png')\n",
    "    image_list.append(f'images/{i+60}.png')\n",
    "\n",
    "    #Scrape for data\n",
    "    new_table = new_soup.find('table',\n",
    "                              attrs={'class': 'data table additional-attributes'})\n",
    "    new_table_body = new_table.find('tbody')\n",
    "    headers = [header.text\n",
    "               for header in new_table_body.find_all('th')]\n",
    "    d_body = [body.text\n",
    "               for body in new_table_body.find_all('td')]\n",
    "    book_data = {headers[n]:d_body[n] for n in range(len(d_body))}\n",
    "\n",
    "    json_output.append(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5e0c6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"books.json\", \"w\", encoding='utf8') as final:\n",
    "    json.dump(json_output, final, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "88bc99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"abstract.json\", \"w\", encoding='utf8') as final:\n",
    "    json.dump(clean_abstract, final, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb86a0d2",
   "metadata": {},
   "source": [
    "# ________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382a844",
   "metadata": {},
   "source": [
    "## Writing books to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3f3a8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_the_abstract(abstract):\n",
    "    abstract = abstract.replace('\\r', '')\n",
    "    abstract = abstract.replace('\\n', '')\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "18253b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_list(list_of_items):\n",
    "    items = random.sample(list_of_items, random.randint(1, 9))\n",
    "    items_string = ''\n",
    "    for item in items:\n",
    "        items_string += f'{item},'\n",
    "    items_string = items_string[:-1]\n",
    "    return items_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "faea74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = ['adventure', 'art', 'autobiography', 'biography', 'childrenâ€™s', 'classic', 'comedy', 'comic', 'contemporary', 'crime', 'drama', 'education', 'engineering', 'fantasy', 'finance', 'Greek literature', 'health', 'history', 'literature', 'management', 'math', 'mystery', 'poetry', 'psychology', 'romance', 'science', 'science fiction', 'sociology', 'technology', 'thriller', 'travel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "70b7cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list = [\"Artificial Intelligence\", \"Machine Learning\", \"Robotics\", \"Data Mining\", \"Computer Graphics\", \"Computer Vision\", \"Computer Networks\", \"Operating Systems\", \"Database Systems\", \"Cryptography\", \"Digital Signal Processing\", \"Embedded Systems\", \"High Performance Computing\", \"Human-Computer Interaction\", \"Information Retrieval\", \"Internet of Things\", \"Natural Language Processing\", \"Parallel Computing\", \"Programming Languages\", \"Software Engineering\", \"Algorithms\", \"Big Data\", \"Cloud Computing\", \"Computer Architecture\", \"Computer Security\", \"Data Science\", \"Game Development\", \"Computer Animation\", \"Computer Ethics\", \"Cybersecurity\", \"Computer Science\", \"Electronics\", \"Neural Networks\", \"Deep Learning\", \"Artificial Neural Networks\", \"Computer Organization\", \"Computer Programming\", \"Computational Science\", \"Control Engineering\", \"Database Management\", \"Discrete Mathematics\", \"Distributed Computing\", \"Expert Systems\", \"Finite Element Analysis\", \"Formal Methods\", \"Genetic Algorithms\", \"Image Processing\", \"Information Science\", \"Machine Vision\", \"Mathematical Modeling\", \"Multimedia Computing\", \"Network Security\", \"Neuroscience\", \"Numerical Analysis\", \"Optimization\", \"Pattern Recognition\", \"Robotics Engineering\", \"Simulation and Modeling\", \"Social Network Analysis\", \"Statistical Analysis\", \"Systems Analysis\", \"Virtual Reality\", \"Web Development\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "89df4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_abstract = []\n",
    "for abstract in abstract_list:\n",
    "    clean_abstract.append(clean_the_abstract(abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "56021886",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('book_insertions.txt', 'w') as f:\n",
    "    f.write('INSERT INTO book (title, publisher, isbn, number_of_pages, category, abstract, image, keywords)\\n')\n",
    "    f.write('VALUES ')\n",
    "    for i in range(len(clean_abstract)):\n",
    "        category_string = randomize_list(category_list)\n",
    "        keyword_string = randomize_list(keywords_list)\n",
    "        f.write(f\"('{json_output[i]['Î¤Î¯Ï„Î»Î¿Ï‚']}', '{json_output[i]['Î•ÎºÎ´ÏŒÏ„Î·Ï‚']}', '{json_output[i]['ISBN']}', '{json_output[i]['Î£ÎµÎ»Î¯Î´ÎµÏ‚']}', '{category_string}', '{clean_abstract[i]}', '{image_list[i]}','{keyword_string}'),\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
